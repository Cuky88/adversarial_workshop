{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ipolosukhin/projects/tf_examples/.env/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sets logging to INFO to see all information from TensorFlow.\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = 'dropout_credit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.213179</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375607</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.305682</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5710.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.754464</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209940</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.116951</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.189169</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>23684.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.644226</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.309476</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0.018798</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531529</td>\n",
       "      <td>6501.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010352</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.298354</td>\n",
       "      <td>12454.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964673</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>13700.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>477.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.548458</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209892</td>\n",
       "      <td>11362.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>2058.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0.166284</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.188274</td>\n",
       "      <td>8800.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.221813</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527888</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.602794</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>333.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200923</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430046</td>\n",
       "      <td>12300.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.025656</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0.475841</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241104</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075427</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.085512</td>\n",
       "      <td>7916.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.046560</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241622</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.392248</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1.595253</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097672</td>\n",
       "      <td>8333.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.034421</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042383</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0.452516</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.392995</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>0.436103</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149971</th>\n",
       "      <td>0</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253855</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149972</th>\n",
       "      <td>0</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149973</th>\n",
       "      <td>0</td>\n",
       "      <td>0.071273</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>6945.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149974</th>\n",
       "      <td>0</td>\n",
       "      <td>1.026395</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494819</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149975</th>\n",
       "      <td>0</td>\n",
       "      <td>0.962721</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>0.603479</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149976</th>\n",
       "      <td>0</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>2716.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149977</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149978</th>\n",
       "      <td>0</td>\n",
       "      <td>0.236450</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>349.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149979</th>\n",
       "      <td>0</td>\n",
       "      <td>0.917635</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>0.259496</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149980</th>\n",
       "      <td>1</td>\n",
       "      <td>0.224711</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>8700.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149981</th>\n",
       "      <td>0</td>\n",
       "      <td>0.067644</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149982</th>\n",
       "      <td>0</td>\n",
       "      <td>0.810012</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121752</td>\n",
       "      <td>6849.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149983</th>\n",
       "      <td>0</td>\n",
       "      <td>0.021046</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250272</td>\n",
       "      <td>2760.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149984</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149985</th>\n",
       "      <td>0</td>\n",
       "      <td>0.037548</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149986</th>\n",
       "      <td>0</td>\n",
       "      <td>0.954409</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149987</th>\n",
       "      <td>0</td>\n",
       "      <td>0.168102</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.080384</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149988</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055692</td>\n",
       "      <td>3249.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149989</th>\n",
       "      <td>0</td>\n",
       "      <td>0.902051</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347924</td>\n",
       "      <td>7515.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149990</th>\n",
       "      <td>0</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>9233.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149991</th>\n",
       "      <td>0</td>\n",
       "      <td>0.055518</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609779</td>\n",
       "      <td>4335.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149992</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104112</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0.477658</td>\n",
       "      <td>10316.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149993</th>\n",
       "      <td>0</td>\n",
       "      <td>0.871976</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>4132.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149994</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>820.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>0</td>\n",
       "      <td>0.385742</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.404293</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>0</td>\n",
       "      <td>0.040674</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225131</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>0</td>\n",
       "      <td>0.299745</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0.716562</td>\n",
       "      <td>5584.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>0</td>\n",
       "      <td>0.246044</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>3870.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5716.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150000</th>\n",
       "      <td>0</td>\n",
       "      <td>0.850283</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249908</td>\n",
       "      <td>8158.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                      1                              0.766127   45   \n",
       "2                      0                              0.957151   40   \n",
       "3                      0                              0.658180   38   \n",
       "4                      0                              0.233810   30   \n",
       "5                      0                              0.907239   49   \n",
       "6                      0                              0.213179   74   \n",
       "7                      0                              0.305682   57   \n",
       "8                      0                              0.754464   39   \n",
       "9                      0                              0.116951   27   \n",
       "10                     0                              0.189169   57   \n",
       "11                     0                              0.644226   30   \n",
       "12                     0                              0.018798   51   \n",
       "13                     0                              0.010352   46   \n",
       "14                     1                              0.964673   40   \n",
       "15                     0                              0.019657   76   \n",
       "16                     0                              0.548458   64   \n",
       "17                     0                              0.061086   78   \n",
       "18                     0                              0.166284   53   \n",
       "19                     0                              0.221813   43   \n",
       "20                     0                              0.602794   25   \n",
       "21                     0                              0.200923   43   \n",
       "22                     1                              0.025656   38   \n",
       "23                     0                              1.000000   39   \n",
       "24                     0                              0.075427   32   \n",
       "25                     0                              0.046560   58   \n",
       "26                     1                              0.392248   50   \n",
       "27                     0                              0.052436   58   \n",
       "28                     0                              0.034421   69   \n",
       "29                     0                              0.452516   24   \n",
       "30                     0                              0.392995   58   \n",
       "...                  ...                                   ...  ...   \n",
       "149971                 0                              0.025449   58   \n",
       "149972                 0                              0.058001   83   \n",
       "149973                 0                              0.071273   42   \n",
       "149974                 0                              1.026395   44   \n",
       "149975                 0                              0.962721   61   \n",
       "149976                 0                              0.022088   58   \n",
       "149977                 0                              0.000627   76   \n",
       "149978                 0                              0.236450   29   \n",
       "149979                 0                              0.917635   52   \n",
       "149980                 1                              0.224711   55   \n",
       "149981                 0                              0.067644   64   \n",
       "149982                 0                              0.810012   43   \n",
       "149983                 0                              0.021046   37   \n",
       "149984                 0                              0.002485   82   \n",
       "149985                 0                              0.037548   84   \n",
       "149986                 0                              0.954409   26   \n",
       "149987                 0                              0.168102   49   \n",
       "149988                 0                              1.000000   28   \n",
       "149989                 0                              0.902051   31   \n",
       "149990                 0                              0.013356   62   \n",
       "149991                 0                              0.055518   46   \n",
       "149992                 0                              0.104112   59   \n",
       "149993                 0                              0.871976   50   \n",
       "149994                 0                              1.000000   22   \n",
       "149995                 0                              0.385742   50   \n",
       "149996                 0                              0.040674   74   \n",
       "149997                 0                              0.299745   44   \n",
       "149998                 0                              0.246044   58   \n",
       "149999                 0                              0.000000   30   \n",
       "150000                 0                              0.850283   64   \n",
       "\n",
       "        NumberOfTime30-59DaysPastDueNotWorse    DebtRatio  MonthlyIncome  \\\n",
       "1                                          2     0.802982         9120.0   \n",
       "2                                          0     0.121876         2600.0   \n",
       "3                                          1     0.085113         3042.0   \n",
       "4                                          0     0.036050         3300.0   \n",
       "5                                          1     0.024926        63588.0   \n",
       "6                                          0     0.375607         3500.0   \n",
       "7                                          0  5710.000000            NaN   \n",
       "8                                          0     0.209940         3500.0   \n",
       "9                                          0    46.000000            NaN   \n",
       "10                                         0     0.606291        23684.0   \n",
       "11                                         0     0.309476         2500.0   \n",
       "12                                         0     0.531529         6501.0   \n",
       "13                                         0     0.298354        12454.0   \n",
       "14                                         3     0.382965        13700.0   \n",
       "15                                         0   477.000000            0.0   \n",
       "16                                         0     0.209892        11362.0   \n",
       "17                                         0  2058.000000            NaN   \n",
       "18                                         0     0.188274         8800.0   \n",
       "19                                         0     0.527888         3280.0   \n",
       "20                                         0     0.065868          333.0   \n",
       "21                                         0     0.430046        12300.0   \n",
       "22                                         0     0.475841         3000.0   \n",
       "23                                         0     0.241104         2500.0   \n",
       "24                                         0     0.085512         7916.0   \n",
       "25                                         0     0.241622         2416.0   \n",
       "26                                         0     1.595253         4676.0   \n",
       "27                                         0     0.097672         8333.0   \n",
       "28                                         0     0.042383         2500.0   \n",
       "29                                         0     0.011761         3400.0   \n",
       "30                                         2     0.436103         5500.0   \n",
       "...                                      ...          ...            ...   \n",
       "149971                                     0     0.253855        15500.0   \n",
       "149972                                     0     0.013997         5000.0   \n",
       "149973                                     0     0.008638         6945.0   \n",
       "149974                                     0     0.494819         5500.0   \n",
       "149975                                     2     0.603479         5000.0   \n",
       "149976                                     0  2716.000000            NaN   \n",
       "149977                                     0    60.000000            NaN   \n",
       "149978                                     0   349.000000            NaN   \n",
       "149979                                     2     0.259496         2500.0   \n",
       "149980                                     0     0.057235         8700.0   \n",
       "149981                                     0     0.254976         5525.0   \n",
       "149982                                     0     0.121752         6849.0   \n",
       "149983                                     0     0.250272         2760.0   \n",
       "149984                                     0     0.000800         5000.0   \n",
       "149985                                     0    25.000000            NaN   \n",
       "149986                                     0     0.324962         1950.0   \n",
       "149987                                     0     0.080384         5000.0   \n",
       "149988                                     0     0.055692         3249.0   \n",
       "149989                                     1     0.347924         7515.0   \n",
       "149990                                     0     0.001408         9233.0   \n",
       "149991                                     0     0.609779         4335.0   \n",
       "149992                                     0     0.477658        10316.0   \n",
       "149993                                     0  4132.000000            NaN   \n",
       "149994                                     0     0.000000          820.0   \n",
       "149995                                     0     0.404293         3400.0   \n",
       "149996                                     0     0.225131         2100.0   \n",
       "149997                                     0     0.716562         5584.0   \n",
       "149998                                     0  3870.000000            NaN   \n",
       "149999                                     0     0.000000         5716.0   \n",
       "150000                                     0     0.249908         8158.0   \n",
       "\n",
       "        NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                                    13                        0   \n",
       "2                                     4                        0   \n",
       "3                                     2                        1   \n",
       "4                                     5                        0   \n",
       "5                                     7                        0   \n",
       "6                                     3                        0   \n",
       "7                                     8                        0   \n",
       "8                                     8                        0   \n",
       "9                                     2                        0   \n",
       "10                                    9                        0   \n",
       "11                                    5                        0   \n",
       "12                                    7                        0   \n",
       "13                                   13                        0   \n",
       "14                                    9                        3   \n",
       "15                                    6                        0   \n",
       "16                                    7                        0   \n",
       "17                                   10                        0   \n",
       "18                                    7                        0   \n",
       "19                                    7                        0   \n",
       "20                                    2                        0   \n",
       "21                                   10                        0   \n",
       "22                                    7                        0   \n",
       "23                                    4                        0   \n",
       "24                                    6                        0   \n",
       "25                                    9                        0   \n",
       "26                                   14                        0   \n",
       "27                                   22                        0   \n",
       "28                                   17                        0   \n",
       "29                                    1                        0   \n",
       "30                                   15                        0   \n",
       "...                                 ...                      ...   \n",
       "149971                                7                        0   \n",
       "149972                                6                        0   \n",
       "149973                                3                        0   \n",
       "149974                                7                        0   \n",
       "149975                               11                        0   \n",
       "149976                                8                        0   \n",
       "149977                                5                        0   \n",
       "149978                                3                        0   \n",
       "149979                                4                        0   \n",
       "149980                                7                        0   \n",
       "149981                               12                        0   \n",
       "149982                                4                        0   \n",
       "149983                                8                        0   \n",
       "149984                                5                        0   \n",
       "149985                                5                        0   \n",
       "149986                                4                        0   \n",
       "149987                               16                        0   \n",
       "149988                                3                        1   \n",
       "149989                               10                        0   \n",
       "149990                                4                        0   \n",
       "149991                                7                        0   \n",
       "149992                               10                        0   \n",
       "149993                               11                        0   \n",
       "149994                                1                        0   \n",
       "149995                                7                        0   \n",
       "149996                                4                        0   \n",
       "149997                                4                        0   \n",
       "149998                               18                        0   \n",
       "149999                                4                        0   \n",
       "150000                                8                        0   \n",
       "\n",
       "        NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                                  6                                     0   \n",
       "2                                  0                                     0   \n",
       "3                                  0                                     0   \n",
       "4                                  0                                     0   \n",
       "5                                  1                                     0   \n",
       "6                                  1                                     0   \n",
       "7                                  3                                     0   \n",
       "8                                  0                                     0   \n",
       "9                                  0                                     0   \n",
       "10                                 4                                     0   \n",
       "11                                 0                                     0   \n",
       "12                                 2                                     0   \n",
       "13                                 2                                     0   \n",
       "14                                 1                                     1   \n",
       "15                                 1                                     0   \n",
       "16                                 1                                     0   \n",
       "17                                 2                                     0   \n",
       "18                                 0                                     0   \n",
       "19                                 1                                     0   \n",
       "20                                 0                                     0   \n",
       "21                                 2                                     0   \n",
       "22                                 1                                     0   \n",
       "23                                 0                                     0   \n",
       "24                                 0                                     0   \n",
       "25                                 1                                     0   \n",
       "26                                 3                                     0   \n",
       "27                                 1                                     0   \n",
       "28                                 0                                     0   \n",
       "29                                 0                                     0   \n",
       "30                                 1                                     0   \n",
       "...                              ...                                   ...   \n",
       "149971                             2                                     0   \n",
       "149972                             0                                     0   \n",
       "149973                             0                                     0   \n",
       "149974                             1                                     0   \n",
       "149975                             1                                     0   \n",
       "149976                             2                                     0   \n",
       "149977                             0                                     0   \n",
       "149978                             0                                     0   \n",
       "149979                             0                                     0   \n",
       "149980                             0                                     0   \n",
       "149981                             1                                     0   \n",
       "149982                             0                                     0   \n",
       "149983                             0                                     0   \n",
       "149984                             0                                     0   \n",
       "149985                             0                                     0   \n",
       "149986                             0                                     0   \n",
       "149987                             0                                     0   \n",
       "149988                             0                                     0   \n",
       "149989                             1                                     0   \n",
       "149990                             0                                     0   \n",
       "149991                             1                                     0   \n",
       "149992                             2                                     0   \n",
       "149993                             1                                     0   \n",
       "149994                             0                                     0   \n",
       "149995                             0                                     0   \n",
       "149996                             1                                     0   \n",
       "149997                             1                                     0   \n",
       "149998                             1                                     0   \n",
       "149999                             0                                     0   \n",
       "150000                             2                                     0   \n",
       "\n",
       "        NumberOfDependents  \n",
       "1                      2.0  \n",
       "2                      1.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "5                      0.0  \n",
       "6                      1.0  \n",
       "7                      0.0  \n",
       "8                      0.0  \n",
       "9                      NaN  \n",
       "10                     2.0  \n",
       "11                     0.0  \n",
       "12                     2.0  \n",
       "13                     2.0  \n",
       "14                     2.0  \n",
       "15                     0.0  \n",
       "16                     2.0  \n",
       "17                     0.0  \n",
       "18                     0.0  \n",
       "19                     2.0  \n",
       "20                     0.0  \n",
       "21                     0.0  \n",
       "22                     2.0  \n",
       "23                     0.0  \n",
       "24                     0.0  \n",
       "25                     0.0  \n",
       "26                     1.0  \n",
       "27                     0.0  \n",
       "28                     1.0  \n",
       "29                     0.0  \n",
       "30                     0.0  \n",
       "...                    ...  \n",
       "149971                 2.0  \n",
       "149972                 0.0  \n",
       "149973                 1.0  \n",
       "149974                 1.0  \n",
       "149975                 0.0  \n",
       "149976                 0.0  \n",
       "149977                 0.0  \n",
       "149978                 0.0  \n",
       "149979                 0.0  \n",
       "149980                 0.0  \n",
       "149981                 0.0  \n",
       "149982                 4.0  \n",
       "149983                 3.0  \n",
       "149984                 0.0  \n",
       "149985                 0.0  \n",
       "149986                 0.0  \n",
       "149987                 1.0  \n",
       "149988                 0.0  \n",
       "149989                 0.0  \n",
       "149990                 3.0  \n",
       "149991                 2.0  \n",
       "149992                 0.0  \n",
       "149993                 3.0  \n",
       "149994                 0.0  \n",
       "149995                 0.0  \n",
       "149996                 0.0  \n",
       "149997                 2.0  \n",
       "149998                 0.0  \n",
       "149999                 0.0  \n",
       "150000                 0.0  \n",
       "\n",
       "[150000 rows x 11 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data.\n",
    "\n",
    "train = pandas.read_csv('data/cs-training.csv', index_col=0)\n",
    "y = train['SeriousDlqin2yrs']\n",
    "X = train.copy().fillna(0)\n",
    "X.pop('SeriousDlqin2yrs')\n",
    "train_x, test_x, train_y, test_y = learn.estimators._sklearn.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "mean_x, var_x = train_x.mean(), train_x.std()\n",
    "train_x = (train_x - mean_x) / var_x\n",
    "test_x = (test_x - mean_x) / var_x\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=10, default_value=None, dtype=tf.float32)\n",
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Restored model from dropout_credit/dnn/model.ckpt-1000-?????-of-00001\n",
      "INFO:tensorflow:Step 1001: loss = 0.385473\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into dropout_credit/dnn/model.ckpt.\n",
      "INFO:tensorflow:Step 1101: loss = 0.374968\n",
      "INFO:tensorflow:Step 1201: loss = 0.200694\n",
      "INFO:tensorflow:Step 1301: loss = 0.265824\n",
      "INFO:tensorflow:Saving checkpoints for 1301 into dropout_credit/dnn/model.ckpt.\n",
      "INFO:tensorflow:Step 1401: loss = 0.276545\n",
      "INFO:tensorflow:Step 1501: loss = 0.313495\n",
      "INFO:tensorflow:Step 1601: loss = 0.178629\n",
      "INFO:tensorflow:Saving checkpoints for 1601 into dropout_credit/dnn/model.ckpt.\n",
      "INFO:tensorflow:Step 1701: loss = 0.199133\n",
      "INFO:tensorflow:Step 1801: loss = 0.174248\n",
      "INFO:tensorflow:Step 1901: loss = 0.24123\n",
      "INFO:tensorflow:Saving checkpoints for 1901 into dropout_credit/dnn/model.ckpt.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into dropout_credit/dnn/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.175248.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(hidden_units=[10, 10], dropout=None, optimizer=None, feature_columns=[_RealValuedColumn(column_name='', dimension=10, default_value=None, dtype=tf.float32)])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_classifier = learn.DNNClassifier(hidden_units=[10, 10],\n",
    "    feature_columns=[layers.real_valued_column('', dimension=10)], model_dir=BASE_DIR + 'dnn', enable_centered_bias=False)\n",
    "dnn_classifier.fit(x=train_x, y=train_y, steps=2000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n",
      "INFO:tensorflow:Transforming feature_column _RealValuedColumn(column_name='', dimension=10, default_value=None, dtype=tf.float32)\n",
      "INFO:tensorflow:Restored model from dropout_credit/dnn/model.ckpt-2000-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 2000.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 2000 step: loss = 0.206852, auc = 0.794345, accuracy/threshold_0.500000_mean = 0.932567, labels/actual_target_mean = 0.0673333, recall/positive_threshold_0.500000_mean = 0.0341584, labels/prediction_mean = 0.0615701, accuracy/baseline_target_mean = 0.0673333, precision/positive_threshold_0.500000_mean = 0.489362, accuracy = 0.932567\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy/baseline_target_mean</th>\n",
       "      <th>accuracy/threshold_0.500000_mean</th>\n",
       "      <th>auc</th>\n",
       "      <th>global_step</th>\n",
       "      <th>labels/actual_target_mean</th>\n",
       "      <th>labels/prediction_mean</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision/positive_threshold_0.500000_mean</th>\n",
       "      <th>recall/positive_threshold_0.500000_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.932567</td>\n",
       "      <td>0.067333</td>\n",
       "      <td>0.932567</td>\n",
       "      <td>0.794345</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.067333</td>\n",
       "      <td>0.06157</td>\n",
       "      <td>0.206852</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.034158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  accuracy/baseline_target_mean  accuracy/threshold_0.500000_mean  \\\n",
       "0  0.932567                       0.067333                          0.932567   \n",
       "\n",
       "        auc  global_step  labels/actual_target_mean  labels/prediction_mean  \\\n",
       "0  0.794345         2000                   0.067333                 0.06157   \n",
       "\n",
       "       loss  precision/positive_threshold_0.500000_mean  \\\n",
       "0  0.206852                                    0.489362   \n",
       "\n",
       "   recall/positive_threshold_0.500000_mean  \n",
       "0                                 0.034158  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame([dnn_classifier.evaluate(x=test_x, y=test_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Step 1: loss = 0.615057\n",
      "INFO:tensorflow:Step 101: loss = 0.425767\n",
      "INFO:tensorflow:Step 201: loss = 0.194235\n",
      "INFO:tensorflow:Saving checkpoints for 300 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 301: loss = 0.248439\n",
      "INFO:tensorflow:Step 401: loss = 0.254526\n",
      "INFO:tensorflow:Step 501: loss = 0.288615\n",
      "INFO:tensorflow:Saving checkpoints for 600 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 601: loss = 0.167637\n",
      "INFO:tensorflow:Step 701: loss = 0.181214\n",
      "INFO:tensorflow:Step 801: loss = 0.156901\n",
      "INFO:tensorflow:Saving checkpoints for 900 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 901: loss = 0.239568\n",
      "INFO:tensorflow:Step 1001: loss = 0.200687\n",
      "INFO:tensorflow:Step 1101: loss = 0.255807\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 1201: loss = 0.203529\n",
      "INFO:tensorflow:Step 1301: loss = 0.171613\n",
      "INFO:tensorflow:Step 1401: loss = 0.192328\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 1501: loss = 0.133355\n",
      "INFO:tensorflow:Step 1601: loss = 0.155332\n",
      "INFO:tensorflow:Step 1701: loss = 0.225591\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 1801: loss = 0.144005\n",
      "INFO:tensorflow:Step 1901: loss = 0.321231\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into dropout_credit/custom_dnn_weighted/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.195464.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Estimator(params=None)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_dnn_model(feature, target):\n",
    "    target = tf.one_hot(target, 2, 1.0, 0.0)\n",
    "    feature = layers.fully_connected(feature, 30)\n",
    "    feature = layers.fully_connected(feature, 30)\n",
    "    logits = layers.fully_connected(feature, 2, activation_fn=None)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target, weight=tf.select(target == 1, 5.0, 1.0))\n",
    "    train_op = layers.optimize_loss(\n",
    "        loss, tf.contrib.framework.get_global_step(), learning_rate=0.05, \n",
    "        optimizer='Adagrad')\n",
    "    predictions = tf.nn.softmax(logits)[:, 1]\n",
    "    return predictions, loss, train_op\n",
    "\n",
    "custom_dnn_classifier = learn.Estimator(model_fn=custom_dnn_model, model_dir=BASE_DIR + 'custom_dnn_weighted')\n",
    "custom_dnn_classifier.fit(x=train_x, y=train_y, steps=2000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Given features: Tensor(\"input:0\", shape=(?, 10), dtype=float32), required signatures: TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False).\n",
      "WARNING:tensorflow:Given targets: Tensor(\"output:0\", shape=(?,), dtype=int64), required signatures: TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False).\n",
      "INFO:tensorflow:Restored model from dropout_credit/custom_dnn_weighted/model.ckpt-2000-?????-of-00001\n",
      "INFO:tensorflow:Eval steps [0,inf) for training step 2000.\n",
      "INFO:tensorflow:Input iterator is exhausted.\n",
      "INFO:tensorflow:Saving evaluation summary for 2000 step: loss = 0.192983, auc = 0.822858\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>global_step</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.822858</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.192983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc  global_step      loss\n",
       "0  0.822858         2000  0.192983"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame([custom_dnn_classifier.evaluate(\n",
    "            x=test_x, y=test_y,\n",
    "            metrics={'auc': tf.contrib.metrics.streaming_auc})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: dropout_credit/custom_dnn_weighted/model.ckpt-2000-?????-of-00001.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12ba71990>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129ae7b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_prob_custom =  custom_dnn_classifier.predict(x=test_x)\n",
    "th_custom, precision_custom, _ = metrics.precision_recall_curve(test_y, pred_prob_custom)\n",
    "plt.plot(precision_custom, th_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(10)]), is_sparse=False)\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\n",
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Restored model from dropout_credit/dnn_dropout_weighted/model.ckpt-3000-?????-of-00001\n",
      "INFO:tensorflow:Step 3001: loss = 0.335652\n",
      "INFO:tensorflow:Saving checkpoints for 3001 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 3101: loss = 0.322858\n",
      "INFO:tensorflow:Step 3201: loss = 0.174492\n",
      "INFO:tensorflow:Step 3301: loss = 0.240518\n",
      "INFO:tensorflow:Saving checkpoints for 3301 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 3401: loss = 0.248162\n",
      "INFO:tensorflow:Step 3501: loss = 0.294054\n",
      "INFO:tensorflow:Step 3601: loss = 0.156227\n",
      "INFO:tensorflow:Saving checkpoints for 3601 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 3701: loss = 0.178422\n",
      "INFO:tensorflow:Step 3801: loss = 0.183702\n",
      "INFO:tensorflow:Step 3901: loss = 0.249266\n",
      "INFO:tensorflow:Saving checkpoints for 3901 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 4001: loss = 0.19976\n",
      "INFO:tensorflow:Step 4101: loss = 0.306177\n",
      "INFO:tensorflow:Step 4201: loss = 0.204952\n",
      "INFO:tensorflow:Saving checkpoints for 4201 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 4301: loss = 0.19325\n",
      "INFO:tensorflow:Step 4401: loss = 0.202016\n",
      "INFO:tensorflow:Step 4501: loss = 0.147884\n",
      "INFO:tensorflow:Saving checkpoints for 4501 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 4601: loss = 0.138802\n",
      "INFO:tensorflow:Step 4701: loss = 0.226941\n",
      "INFO:tensorflow:Step 4801: loss = 0.16091\n",
      "INFO:tensorflow:Saving checkpoints for 4801 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Step 4901: loss = 0.342312\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into dropout_credit/dnn_dropout_weighted/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.18013.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Estimator(params=None)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def uncertanty_dnn_model(feature, target, mode):\n",
    "    target = tf.one_hot(target, 2, 1.0, 0.0)\n",
    "    def get_logits(feature, is_training_or_sample):\n",
    "        feature = layers.fully_connected(feature, 30)\n",
    "        feature = layers.dropout(feature, 0.9, is_training=is_training_or_sample)\n",
    "        feature = layers.fully_connected(feature, 30)\n",
    "        feature = layers.dropout(feature, 0.9, is_training=is_training_or_sample)\n",
    "        return layers.fully_connected(feature, 2, activation_fn=None)\n",
    "    with tf.variable_scope('dnn'):\n",
    "        logits = get_logits(feature, mode == learn.ModeKeys.TRAIN)\n",
    "    with tf.variable_scope('dnn', reuse=True):\n",
    "        sampled_logits = get_logits(feature, True)\n",
    "    loss = tf.contrib.losses.softmax_cross_entropy(logits, target, weight=tf.select(target == 1, 5.0, 1.0))\n",
    "    train_op = layers.optimize_loss(\n",
    "        loss, tf.contrib.framework.get_global_step(), learning_rate=0.05, optimizer='Adagrad')\n",
    "    predictions = {'classes': tf.argmax(logits, dimension=1), \n",
    "                   'probabilities': tf.nn.softmax(logits)[:, 1],\n",
    "                   'sampled_probabilities': tf.nn.softmax(sampled_logits)[:, 1]}\n",
    "    return predictions, loss, train_op\n",
    "\n",
    "dropout_dnn_classifier = learn.Estimator(model_fn=uncertanty_dnn_model, model_dir=BASE_DIR + 'dnn_dropout_weighted')\n",
    "dropout_dnn_classifier.fit(x=train_x, y=train_y, steps=2000, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: dropout_credit/dnn_dropout_weighted/model.ckpt-5000-?????-of-00001.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc\n",
       "0  0.830772"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob =  dropout_dnn_classifier.predict(x=test_x, outputs=['probabilities'])['probabilities']\n",
    "pandas.DataFrame([{'auc': metrics.roc_auc_score(test_y, pred_prob)}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c52acd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "th, precision, recall = metrics.precision_recall_curve(test_y, pred_prob)\n",
    "plt.plot(precision, th, c='r')\n",
    "_ = plt.plot(precision_custom, th_custom, c='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
